{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":6146260,"sourceType":"datasetVersion","datasetId":3521629},{"sourceId":6146317,"sourceType":"datasetVersion","datasetId":3524699},{"sourceId":8510781,"sourceType":"datasetVersion","datasetId":5080366}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install blingfire\n!pip install faiss-cpu\n!pip install sentence-transformers\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:36:03.958035Z","iopub.execute_input":"2024-06-13T17:36:03.958512Z","iopub.status.idle":"2024-06-13T17:36:58.104863Z","shell.execute_reply.started":"2024-06-13T17:36:03.958471Z","shell.execute_reply":"2024-06-13T17:36:58.103675Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting blingfire\n  Downloading blingfire-0.1.8-py3-none-any.whl (42.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: blingfire\nSuccessfully installed blingfire-0.1.8\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (1.23.5)\nInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.8.0\nCollecting sentence-transformers\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.65.0)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.1)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.16.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nCollecting huggingface-hub>=0.15.1 (from sentence-transformers)\n  Downloading huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.6.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hCollecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers, sentence-transformers\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.3.1\n    Uninstalling safetensors-0.3.1:\n      Successfully uninstalled safetensors-0.3.1\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.16.4\n    Uninstalling huggingface-hub-0.16.4:\n      Successfully uninstalled huggingface-hub-0.16.4\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.13.3\n    Uninstalling tokenizers-0.13.3:\n      Successfully uninstalled tokenizers-0.13.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.2\n    Uninstalling transformers-4.30.2:\n      Successfully uninstalled transformers-4.30.2\nSuccessfully installed huggingface-hub-0.23.3 safetensors-0.4.3 sentence-transformers-3.0.1 tokenizers-0.19.1 transformers-4.41.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nfrom tqdm.autonotebook import tqdm, trange\nimport torch\nimport blingfire as bf\nfrom collections.abc import Iterable\n\nimport faiss\nfrom faiss import write_index, read_index\n\nimport os\n\nfrom typing import Optional, Union\nimport pandas as pd, numpy as np, torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer\nfrom transformers import EarlyStoppingCallback\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:26:14.056925Z","iopub.execute_input":"2024-06-13T18:26:14.057366Z","iopub.status.idle":"2024-06-13T18:26:14.066224Z","shell.execute_reply.started":"2024-06-13T18:26:14.057332Z","shell.execute_reply":"2024-06-13T18:26:14.064777Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"model_name = 'sentence-transformers/all-MiniLM-L6-v2'\ndimension = 384\nmax_length = 384\nbatch_size = 16\nif torch.cuda.is_available():\n  device = 'cuda'\nelse:\n device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:57:38.600254Z","iopub.execute_input":"2024-06-13T17:57:38.601319Z","iopub.status.idle":"2024-06-13T17:57:38.607696Z","shell.execute_reply.started":"2024-06-13T17:57:38.601269Z","shell.execute_reply":"2024-06-13T17:57:38.606416Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"wikipedia_path = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(wikipedia_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:57:39.437900Z","iopub.execute_input":"2024-06-13T17:57:39.438338Z","iopub.status.idle":"2024-06-13T17:57:39.449014Z","shell.execute_reply.started":"2024-06-13T17:57:39.438302Z","shell.execute_reply":"2024-06-13T17:57:39.447737Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer(model_name,device=device)\nmodel.max_length = 384\nmodel = model ","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:57:39.836962Z","iopub.execute_input":"2024-06-13T17:57:39.837389Z","iopub.status.idle":"2024-06-13T17:57:41.604566Z","shell.execute_reply.started":"2024-06-13T17:57:39.837355Z","shell.execute_reply":"2024-06-13T17:57:41.603429Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"sentence_index = read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:57:41.606488Z","iopub.execute_input":"2024-06-13T17:57:41.606869Z","iopub.status.idle":"2024-06-13T17:58:06.023977Z","shell.execute_reply.started":"2024-06-13T17:57:41.606837Z","shell.execute_reply":"2024-06-13T17:58:06.022695Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"row = {}\nrow['prompt'] = \"Which of the following philosophers or scientists is associated with the view that space is absolute and exists permanently and independently of matter?\"\nrow['A'] = 'Plato'\nrow['B'] = 'Aristotle'\nrow['C'] = 'Alhazen'\nrow['D'] = 'Isaac Newton'\nrow['E'] = 'George Berkeley'\nrow['id'] = 0\ntrain = pd.DataFrame([row])","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:58:06.025694Z","iopub.execute_input":"2024-06-13T17:58:06.026060Z","iopub.status.idle":"2024-06-13T17:58:06.033330Z","shell.execute_reply.started":"2024-06-13T17:58:06.026028Z","shell.execute_reply":"2024-06-13T17:58:06.032159Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:58:06.035408Z","iopub.execute_input":"2024-06-13T17:58:06.035881Z","iopub.status.idle":"2024-06-13T17:58:06.056174Z","shell.execute_reply.started":"2024-06-13T17:58:06.035848Z","shell.execute_reply":"2024-06-13T17:58:06.054926Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                              prompt      A          B  \\\n0  Which of the following philosophers or scienti...  Plato  Aristotle   \n\n         C             D                E  id  \n0  Alhazen  Isaac Newton  George Berkeley   0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Which of the following philosophers or scienti...</td>\n      <td>Plato</td>\n      <td>Aristotle</td>\n      <td>Alhazen</td>\n      <td>Isaac Newton</td>\n      <td>George Berkeley</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"prompt_embeddings = model.encode(train.prompt.values, batch_size=batch_size, device=device, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True).half()\nprompt_embeddings = prompt_embeddings.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:58:06.058183Z","iopub.execute_input":"2024-06-13T17:58:06.058651Z","iopub.status.idle":"2024-06-13T17:58:06.228625Z","shell.execute_reply.started":"2024-06-13T17:58:06.058608Z","shell.execute_reply":"2024-06-13T17:58:06.227423Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2f65cb2176b438fa523e6980d8e01c6"}},"metadata":{}}]},{"cell_type":"code","source":"search_score, search_index = sentence_index.search(prompt_embeddings, 5)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:58:43.615173Z","iopub.execute_input":"2024-06-13T17:58:43.615650Z","iopub.status.idle":"2024-06-13T17:58:44.623485Z","shell.execute_reply.started":"2024-06-13T17:58:43.615614Z","shell.execute_reply":"2024-06-13T17:58:44.622194Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\", columns=['id', 'file'])","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:59:00.109046Z","iopub.execute_input":"2024-06-13T17:59:00.109508Z","iopub.status.idle":"2024-06-13T17:59:04.970600Z","shell.execute_reply.started":"2024-06-13T17:59:00.109472Z","shell.execute_reply":"2024-06-13T17:59:04.969529Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"## Get the article and associated file location using the index\nwikipedia_file_data = []\n\nfor i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n    \n    scr_idx = idx\n    _df = df.loc[scr_idx].copy()\n    _df['prompt_id'] = i\n    wikipedia_file_data.append(_df)\nwikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\nwikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:59:18.656319Z","iopub.execute_input":"2024-06-13T17:59:18.656749Z","iopub.status.idle":"2024-06-13T17:59:18.709511Z","shell.execute_reply.started":"2024-06-13T17:59:18.656715Z","shell.execute_reply":"2024-06-13T17:59:18.708200Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764ac826bf704580ab6bdbd3d21383e1"}},"metadata":{}}]},{"cell_type":"code","source":"## Get the full text data\nwiki_text_data = []\n\nfor file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n    _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data['file']==file]['id'].tolist()]\n    _df = pd.read_parquet(f\"{wikipedia_path}/{file}\", columns=['id', 'text'])\n\n    _df = _df[_df['id'].isin(_id)]\n    wiki_text_data.append(_df)\n    _ = gc.collect()\nwiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T17:59:35.001660Z","iopub.execute_input":"2024-06-13T17:59:35.002086Z","iopub.status.idle":"2024-06-13T18:00:13.660604Z","shell.execute_reply.started":"2024-06-13T17:59:35.002045Z","shell.execute_reply":"2024-06-13T18:00:13.659229Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1ae99ec62934aa0be8d5feb024055f7"}},"metadata":{}}]},{"cell_type":"code","source":"def process_pages(pages: Iterable[str],page_ids : Iterable , split_sentences=True,filter_length = 3):\n    df = sectionize_pages(pages,page_ids)\n    \n    if split_sentences:\n        df = sentencize(df.text.values,df.page_id,df.offset.values,filter_length)\n    return df\n    \ndef sectionize_pages(pages,page_ids):\n    processed_text = []\n    for page,page_id in tqdm(zip(pages,page_ids),total=len(pages)):\n        row={}\n        text,start,end = page,0,len(page)\n        row['page_id']=page_id\n        row['text']=text\n        row['offset']=(start,end)\n        processed_text.append(row)\n    df = pd.DataFrame(processed_text)\n    return df.reset_index(drop=True)\n\n        \ndef  sentencize(pages : Iterable[str],page_ids : Iterable , offsets : Iterable[tuple[int,int]],filter_length : int = 3 ):\n    page_sentences = []\n    for page,page_id,offset in tqdm(zip(pages,page_ids,offsets),total=len(pages)):\n        try:\n            _,sentence_offsets = bf.text_to_sentences_and_offsets(page)\n            for i in sentence_offsets:\n                if i[1]-i[0] > filter_length:\n                    sentence=page[i[0]:i[1]]\n                    abs_offset = (i[0]+offset[0],i[1]+offset[0])\n                    row={}\n                    row['page_id']=page_id\n                    row['offset']=abs_offset\n                    row['text']=sentence\n                    page_sentences.append(row)\n        except:\n            continue\n            \n    return pd.DataFrame(page_sentences)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:00:13.663027Z","iopub.execute_input":"2024-06-13T18:00:13.663987Z","iopub.status.idle":"2024-06-13T18:00:13.677912Z","shell.execute_reply.started":"2024-06-13T18:00:13.663940Z","shell.execute_reply":"2024-06-13T18:00:13.676628Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"processed_wiki_text_data = process_pages(wiki_text_data.text.values, wiki_text_data.id.values)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:00:27.526168Z","iopub.execute_input":"2024-06-13T18:00:27.526608Z","iopub.status.idle":"2024-06-13T18:00:27.649356Z","shell.execute_reply.started":"2024-06-13T18:00:27.526573Z","shell.execute_reply":"2024-06-13T18:00:27.648238Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"340352c98f214379aa77e4ab8bd638f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e6630f7dd7f4c55a50a96f624877972"}},"metadata":{}}]},{"cell_type":"code","source":"wiki_text_embeddings = model.encode(processed_wiki_text_data.text,batch_size=batch_size,device=device,show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True).half()\nwiki_text_embeddings=wiki_text_embeddings.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:00:42.847290Z","iopub.execute_input":"2024-06-13T18:00:42.847714Z","iopub.status.idle":"2024-06-13T18:00:50.869942Z","shell.execute_reply.started":"2024-06-13T18:00:42.847681Z","shell.execute_reply":"2024-06-13T18:00:50.868603Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/43 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e0e621eeb224faca4e431cddf7da167"}},"metadata":{}}]},{"cell_type":"code","source":"train['answers'] = train.apply(lambda x: \" \".join([x['A'],x['B'],x['C'],x['D'],x['E']]),axis=1)\ntrain['qna'] = train['prompt']+' '+train['answers']","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:00:59.535845Z","iopub.execute_input":"2024-06-13T18:00:59.536272Z","iopub.status.idle":"2024-06-13T18:00:59.545860Z","shell.execute_reply.started":"2024-06-13T18:00:59.536229Z","shell.execute_reply":"2024-06-13T18:00:59.544672Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"questions_embeddings = model.encode(train.qna.values,batch_size=batch_size,device=device,show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True).half()\nquestions_embeddings = questions_embeddings.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:01:28.506613Z","iopub.execute_input":"2024-06-13T18:01:28.507092Z","iopub.status.idle":"2024-06-13T18:01:28.556645Z","shell.execute_reply.started":"2024-06-13T18:01:28.507054Z","shell.execute_reply":"2024-06-13T18:01:28.555581Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f2831d009d048448842b9a53b683495"}},"metadata":{}}]},{"cell_type":"code","source":"num_sentences = 5\nprompt_contexts = []\ncontexts = []\n\nfor r in train.itertuples():\n    q_context = \"\"\n    prompt_id = r.id\n    \n    prompt_indices = processed_wiki_text_data[processed_wiki_text_data['page_id'].isin(wikipedia_file_data[wikipedia_file_data['prompt_id'] == prompt_id]['id'].values)].index.values\n    \n    q_context = \"Question: \"+train.prompt.iloc[prompt_id]+'\\n'\n    \n    q_context += '(A) ' + train.A.iloc[prompt_id] + '\\n'\n    q_context += '(B) ' + train.B.iloc[prompt_id] + '\\n'\n    q_context += '(C) ' + train.C.iloc[prompt_id] + '\\n'\n    q_context += '(D) ' + train.D.iloc[prompt_id] + '\\n'\n    q_context += '(E) ' + train.E.iloc[prompt_id] + '\\n'\n    \n    if prompt_indices.shape[0] > 0 :\n        q_context += 'Context : \\n'\n        prompt_index = faiss.index_factory(wiki_text_embeddings.shape[1], \"Flat\")\n        prompt_index.add(wiki_text_embeddings[prompt_indices])\n        \n        context = \"\"\n        \n        ## Get the top matches\n        ss, ii = prompt_index.search(questions_embeddings, num_sentences)\n        \n        for _s,_i in zip(ss[prompt_id],ii[prompt_id]):\n            if _s < 2:\n                context +=  processed_wiki_text_data.loc[prompt_indices[_i]]['text'] + '\\n'\n        q_context += context\n    contexts.append(context)\n    prompt_contexts.append(q_context)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:01:44.480219Z","iopub.execute_input":"2024-06-13T18:01:44.480678Z","iopub.status.idle":"2024-06-13T18:01:44.508533Z","shell.execute_reply.started":"2024-06-13T18:01:44.480639Z","shell.execute_reply":"2024-06-13T18:01:44.507311Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train['context'] = contexts","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:01:56.902794Z","iopub.execute_input":"2024-06-13T18:01:56.903238Z","iopub.status.idle":"2024-06-13T18:01:56.910194Z","shell.execute_reply.started":"2024-06-13T18:01:56.903202Z","shell.execute_reply":"2024-06-13T18:01:56.908820Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train = train.drop(columns=['answers','qna'])","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:15:48.896909Z","iopub.execute_input":"2024-06-13T18:15:48.897347Z","iopub.status.idle":"2024-06-13T18:15:52.166685Z","shell.execute_reply.started":"2024-06-13T18:15:48.897311Z","shell.execute_reply":"2024-06-13T18:15:52.165254Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 train = train.drop(columns=[\u001b[33m'\u001b[0m\u001b[33manswers\u001b[0m\u001b[33m'\u001b[0m,\u001b[33m'\u001b[0m\u001b[33mqna\u001b[0m\u001b[33m'\u001b[0m])                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/util/\u001b[0m\u001b[1;33m_decorators.py\u001b[0m:\u001b[94m331\u001b[0m in \u001b[92mwrapper\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mFutureWarning\u001b[0m,                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mstacklevel=find_stack_level(),                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m331 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m332 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# attribute \"__signature__\"\u001b[0m                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mframe.py\u001b[0m:\u001b[94m5399\u001b[0m in \u001b[92mdrop\u001b[0m                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5396 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mfalcon  speed   320.0   250.0\u001b[0m                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5397 \u001b[0m\u001b[2;33m│   │   │   │   \u001b[0m\u001b[33mweight  1.0     0.8\u001b[0m                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5398 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 5399 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().drop(                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5400 \u001b[0m\u001b[2m│   │   │   \u001b[0mlabels=labels,                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5401 \u001b[0m\u001b[2m│   │   │   \u001b[0maxis=axis,                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5402 \u001b[0m\u001b[2m│   │   │   \u001b[0mindex=index,                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/util/\u001b[0m\u001b[1;33m_decorators.py\u001b[0m:\u001b[94m331\u001b[0m in \u001b[92mwrapper\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mFutureWarning\u001b[0m,                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mstacklevel=find_stack_level(),                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m331 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m332 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# attribute \"__signature__\"\u001b[0m                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m4505\u001b[0m in \u001b[92mdrop\u001b[0m                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4502 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4503 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m axis, labels \u001b[95min\u001b[0m axes.items():                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4504 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m labels \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 4505 \u001b[2m│   │   │   │   \u001b[0mobj = obj._drop_axis(labels, axis, level=level, errors=errors)           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4506 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4507 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m inplace:                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4508 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._update_inplace(obj)                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m4546\u001b[0m in \u001b[92m_drop_axis\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4543 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAssertionError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33maxis must be a MultiIndex\u001b[0m\u001b[33m\"\u001b[0m)                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4544 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mnew_axis = axis.drop(labels, level=level, errors=errors)                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4545 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 4546 \u001b[2m│   │   │   │   \u001b[0mnew_axis = axis.drop(labels, errors=errors)                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4547 \u001b[0m\u001b[2m│   │   │   \u001b[0mindexer = axis.get_indexer(new_axis)                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4548 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4549 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Case for non-unique axis\u001b[0m                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m6934\u001b[0m in \u001b[92mdrop\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m6931 \u001b[0m\u001b[2m│   │   \u001b[0mmask = indexer == -\u001b[94m1\u001b[0m                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m6932 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mask.any():                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m6933 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m errors != \u001b[33m\"\u001b[0m\u001b[33mignore\u001b[0m\u001b[33m\"\u001b[0m:                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m6934 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0m\u001b[96mlist\u001b[0m(labels[mask])\u001b[33m}\u001b[0m\u001b[33m not found in axis\u001b[0m\u001b[33m\"\u001b[0m)                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m6935 \u001b[0m\u001b[2m│   │   │   \u001b[0mindexer = indexer[~mask]                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m6936 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.delete(indexer)                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m6937 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mKeyError: \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m'answers', 'qna'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m not found in axis\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 train = train.drop(columns=[<span style=\"color: #808000; text-decoration-color: #808000\">'answers'</span>,<span style=\"color: #808000; text-decoration-color: #808000\">'qna'</span>])                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/util/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_decorators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">331</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">328 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">FutureWarning</span>,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>stacklevel=find_stack_level(),                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">330 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>331 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">332 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">333 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">334 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># attribute \"__signature__\"</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">frame.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5399</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">drop</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5396 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">falcon  speed   320.0   250.0</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5397 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">weight  1.0     0.8</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5398 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 5399 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().drop(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5400 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>labels=labels,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5401 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>axis=axis,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5402 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>index=index,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/util/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_decorators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">331</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">328 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">FutureWarning</span>,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">329 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>stacklevel=find_stack_level(),                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">330 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>331 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">332 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">333 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">334 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># attribute \"__signature__\"</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">generic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4505</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">drop</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> axis, labels <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> axes.items():                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> labels <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 4505 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>obj = obj._drop_axis(labels, axis, level=level, errors=errors)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4506 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4507 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> inplace:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4508 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._update_inplace(obj)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">generic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4546</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_drop_axis</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4543 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AssertionError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"axis must be a MultiIndex\"</span>)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>new_axis = axis.drop(labels, level=level, errors=errors)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4545 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 4546 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>new_axis = axis.drop(labels, errors=errors)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4547 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>indexer = axis.get_indexer(new_axis)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4548 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4549 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Case for non-unique axis</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6934</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">drop</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6931 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>mask = indexer == -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6932 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> mask.any():                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6933 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> errors != <span style=\"color: #808000; text-decoration-color: #808000\">\"ignore\"</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>6934 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(labels[mask])<span style=\"color: #808000; text-decoration-color: #808000\">} not found in axis\"</span>)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6935 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>indexer = indexer[~mask]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6936 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.delete(indexer)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6937 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">\"['answers', 'qna'] not found in axis\"</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"train[\"prompt\"] = train[\"context\"].apply(lambda x: x[:1750]) + \" #### \" +  train[\"prompt\"]\ntrain['answer'] = 'A'\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:16:07.869604Z","iopub.execute_input":"2024-06-13T18:16:07.870051Z","iopub.status.idle":"2024-06-13T18:16:07.887358Z","shell.execute_reply.started":"2024-06-13T18:16:07.870014Z","shell.execute_reply":"2024-06-13T18:16:07.886017Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"                                              prompt      A          B  \\\n0  The absolute point of view was advocated in ph...  Plato  Aristotle   \n\n         C             D                E  id  \\\n0  Alhazen  Isaac Newton  George Berkeley   0   \n\n                                             context answer  \n0  The absolute point of view was advocated in ph...      A  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>id</th>\n      <th>context</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The absolute point of view was advocated in ph...</td>\n      <td>Plato</td>\n      <td>Aristotle</td>\n      <td>Alhazen</td>\n      <td>Isaac Newton</td>\n      <td>George Berkeley</td>\n      <td>0</td>\n      <td>The absolute point of view was advocated in ph...</td>\n      <td>A</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model_dir = \"/kaggle/input/llm-science-model/model_v2\"\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:22:53.625285Z","iopub.execute_input":"2024-06-13T18:22:53.626817Z","iopub.status.idle":"2024-06-13T18:23:05.219737Z","shell.execute_reply.started":"2024-06-13T18:22:53.626766Z","shell.execute_reply":"2024-06-13T18:23:05.218334Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForMultipleChoice(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-23): 24 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): StableDropout()\n  )\n  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n  (dropout): StableDropout()\n)"},"metadata":{}}]},{"cell_type":"code","source":"# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\noptions = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(example):\n    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n    # so we'll copy our question 5 times before tokenizing\n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    # Our tokenizer will turn our text into token IDs BERT can understand\n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:24:01.704944Z","iopub.execute_input":"2024-06-13T18:24:01.706140Z","iopub.status.idle":"2024-06-13T18:24:01.713968Z","shell.execute_reply.started":"2024-06-13T18:24:01.706098Z","shell.execute_reply":"2024-06-13T18:24:01.712502Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:24:18.621196Z","iopub.execute_input":"2024-06-13T18:24:18.621668Z","iopub.status.idle":"2024-06-13T18:24:18.633317Z","shell.execute_reply.started":"2024-06-13T18:24:18.621632Z","shell.execute_reply":"2024-06-13T18:24:18.631829Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset = Dataset.from_pandas(train[['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer']].drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\n#tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"__index_level_0__\"])\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\ntest_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, shuffle=False, collate_fn=data_collator)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:26:22.511662Z","iopub.execute_input":"2024-06-13T18:26:22.512098Z","iopub.status.idle":"2024-06-13T18:26:22.558922Z","shell.execute_reply.started":"2024-06-13T18:26:22.512065Z","shell.execute_reply":"2024-06-13T18:26:22.557727Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15244876ca2d4c6abc46545392bbcce6"}},"metadata":{}}]},{"cell_type":"code","source":"test_predictions = []\nfor batch in test_dataloader:\n    for k in batch.keys():\n        batch[k] = batch[k]\n    with torch.no_grad():\n        outputs = model(**batch)\n    test_predictions.append(outputs.logits.cpu().detach())\n\ntest_predictions = torch.cat(test_predictions)\ntest_predictions = test_predictions.numpy()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:31:09.821029Z","iopub.execute_input":"2024-06-13T18:31:09.822085Z","iopub.status.idle":"2024-06-13T18:31:46.848628Z","shell.execute_reply.started":"2024-06-13T18:31:09.822045Z","shell.execute_reply":"2024-06-13T18:31:46.847501Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"index_of_max = np.argmax(test_predictions)\ncorrect = index_to_option[index_of_max]","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:35:56.060984Z","iopub.execute_input":"2024-06-13T18:35:56.061423Z","iopub.status.idle":"2024-06-13T18:35:56.067393Z","shell.execute_reply.started":"2024-06-13T18:35:56.061388Z","shell.execute_reply":"2024-06-13T18:35:56.066149Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"correct","metadata":{"execution":{"iopub.status.busy":"2024-06-13T18:36:04.427691Z","iopub.execute_input":"2024-06-13T18:36:04.428134Z","iopub.status.idle":"2024-06-13T18:36:04.435184Z","shell.execute_reply.started":"2024-06-13T18:36:04.428099Z","shell.execute_reply":"2024-06-13T18:36:04.433914Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"'D'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}