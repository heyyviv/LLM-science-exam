{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":3680037,"sourceType":"datasetVersion","datasetId":2202288},{"sourceId":4988409,"sourceType":"datasetVersion","datasetId":2893282},{"sourceId":5632975,"sourceType":"datasetVersion","datasetId":3238926},{"sourceId":6146260,"sourceType":"datasetVersion","datasetId":3521629},{"sourceId":6146317,"sourceType":"datasetVersion","datasetId":3524699},{"sourceId":6149251,"sourceType":"datasetVersion","datasetId":3526632},{"sourceId":6300474,"sourceType":"datasetVersion","datasetId":3520954},{"sourceId":6359953,"sourceType":"datasetVersion","datasetId":3663541},{"sourceId":6572938,"sourceType":"datasetVersion","datasetId":3600418},{"sourceId":8510781,"sourceType":"datasetVersion","datasetId":5080366},{"sourceId":141695423,"sourceType":"kernelVersion"}],"dockerImageVersionId":30528,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# installing offline dependencies\n!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n!pip install -U /kaggle/working/sentence-transformers\n!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n\n!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":126.809817,"end_time":"2023-08-14T10:09:22.925969","exception":false,"start_time":"2023-08-14T10:07:16.116152","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:48:57.902434Z","iopub.execute_input":"2024-05-25T03:48:57.902729Z","iopub.status.idle":"2024-05-25T03:51:00.508281Z","shell.execute_reply.started":"2024-05-25T03:48:57.902702Z","shell.execute_reply":"2024-05-25T03:51:00.507115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm.auto import tqdm\nimport blingfire as bf\nfrom __future__ import annotations\n\nfrom collections.abc import Iterable\n\nimport faiss\nfrom faiss import write_index, read_index\n\nfrom sentence_transformers import SentenceTransformer\n\nimport torch\nimport ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")\n\nfrom dataclasses import dataclass\nfrom typing import Optional, Union\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom torch.utils.data import DataLoader","metadata":{"papermill":{"duration":8.534957,"end_time":"2023-08-14T10:09:31.474781","exception":false,"start_time":"2023-08-14T10:09:22.939824","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:51:00.510458Z","iopub.execute_input":"2024-05-25T03:51:00.510789Z","iopub.status.idle":"2024-05-25T03:51:14.082504Z","shell.execute_reply.started":"2024-05-25T03:51:00.510753Z","shell.execute_reply":"2024-05-25T03:51:14.081746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_documents(documents: Iterable[str],\n                      document_ids: Iterable,\n                      split_sentences: bool = True,\n                      filter_len: int = 3,\n                      disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Main helper function to process documents from the EMR.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param document_type: String denoting the document type to be processed\n    :param document_sections: List of sections for a given document type to process\n    :param split_sentences: Flag to determine whether to further split sections into sentences\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n    \n    df = sectionize_documents(documents, document_ids, disable_progress_bar)\n\n    if split_sentences:\n        df = sentencize(df.text.values, \n                        df.document_id.values,\n                        df.offset.values, \n                        filter_len, \n                        disable_progress_bar)\n    return df\n\n\ndef sectionize_documents(documents: Iterable[str],\n                         document_ids: Iterable,\n                         disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Obtains the sections of the imaging reports and returns only the \n    selected sections (defaults to FINDINGS, IMPRESSION, and ADDENDUM).\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `offset`\n    \"\"\"\n    processed_documents = []\n    for document_id, document in tqdm(zip(document_ids, documents), total=len(documents), disable=disable_progress_bar):\n        row = {}\n        text, start, end = (document, 0, len(document))\n        row['document_id'] = document_id\n        row['text'] = text\n        row['offset'] = (start, end)\n\n        processed_documents.append(row)\n\n    _df = pd.DataFrame(processed_documents)\n    if _df.shape[0] > 0:\n        return _df.sort_values(['document_id', 'offset']).reset_index(drop=True)\n    else:\n        return _df\n\n\ndef sentencize(documents: Iterable[str],\n               document_ids: Iterable,\n               offsets: Iterable[tuple[int, int]],\n               filter_len: int = 3,\n               disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Split a document into sentences. Can be used with `sectionize_documents`\n    to further split documents into more manageable pieces. Takes in offsets\n    to ensure that after splitting, the sentences can be matched to the\n    location in the original documents.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param offsets: Iterable tuple of the start and end indices\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n\n    document_sentences = []\n    for document, document_id, offset in tqdm(zip(documents, document_ids, offsets), total=len(documents), disable=disable_progress_bar):\n        try:\n            _, sentence_offsets = bf.text_to_sentences_and_offsets(document)\n            for o in sentence_offsets:\n                if o[1]-o[0] > filter_len:\n                    sentence = document[o[0]:o[1]]\n                    abs_offsets = (o[0]+offset[0], o[1]+offset[0])\n                    row = {}\n                    row['document_id'] = document_id\n                    row['text'] = sentence\n                    row['offset'] = abs_offsets\n                    document_sentences.append(row)\n        except:\n            continue\n    return pd.DataFrame(document_sentences)","metadata":{"papermill":{"duration":0.034054,"end_time":"2023-08-14T10:09:31.574046","exception":false,"start_time":"2023-08-14T10:09:31.539992","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:51:14.083701Z","iopub.execute_input":"2024-05-25T03:51:14.083991Z","iopub.status.idle":"2024-05-25T03:51:14.099099Z","shell.execute_reply.started":"2024-05-25T03:51:14.083966Z","shell.execute_reply":"2024-05-25T03:51:14.098256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIM_MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\nDEVICE = 0\nMAX_LENGTH = 384\nBATCH_SIZE = 16\n\nWIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(WIKI_PATH)","metadata":{"papermill":{"duration":0.036342,"end_time":"2023-08-14T10:09:31.623595","exception":false,"start_time":"2023-08-14T10:09:31.587253","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:51:31.770762Z","iopub.execute_input":"2024-05-25T03:51:31.771621Z","iopub.status.idle":"2024-05-25T03:51:31.781566Z","shell.execute_reply.started":"2024-05-25T03:51:31.771586Z","shell.execute_reply":"2024-05-25T03:51:31.780772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Relevant Title Retrieval","metadata":{}},{"cell_type":"code","source":"trn = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\").drop(\"id\", 1)\ntrn.head()","metadata":{"papermill":{"duration":0.058533,"end_time":"2023-08-14T10:09:31.695383","exception":false,"start_time":"2023-08-14T10:09:31.63685","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:51:32.884264Z","iopub.execute_input":"2024-05-25T03:51:32.884612Z","iopub.status.idle":"2024-05-25T03:51:32.927617Z","shell.execute_reply.started":"2024-05-25T03:51:32.884583Z","shell.execute_reply":"2024-05-25T03:51:32.926705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SentenceTransformer(SIM_MODEL, device='cuda')\nmodel.max_seq_length = MAX_LENGTH\nmodel = model.half()","metadata":{"papermill":{"duration":13.282604,"end_time":"2023-08-14T10:09:44.992949","exception":false,"start_time":"2023-08-14T10:09:31.710345","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:51:33.248539Z","iopub.execute_input":"2024-05-25T03:51:33.249473Z","iopub.status.idle":"2024-05-25T03:51:34.493082Z","shell.execute_reply.started":"2024-05-25T03:51:33.249435Z","shell.execute_reply":"2024-05-25T03:51:34.492107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_index = read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")","metadata":{"papermill":{"duration":95.926417,"end_time":"2023-08-14T10:11:20.934445","exception":false,"start_time":"2023-08-14T10:09:45.008028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:51:34.494866Z","iopub.execute_input":"2024-05-25T03:51:34.495338Z","iopub.status.idle":"2024-05-25T03:52:44.699845Z","shell.execute_reply.started":"2024-05-25T03:51:34.495302Z","shell.execute_reply":"2024-05-25T03:52:44.698910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_embeddings = model.encode(trn.prompt.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nprompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n_ = gc.collect()","metadata":{"papermill":{"duration":10.891104,"end_time":"2023-08-14T10:11:31.84869","exception":false,"start_time":"2023-08-14T10:11:20.957586","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:52:44.701382Z","iopub.execute_input":"2024-05-25T03:52:44.701672Z","iopub.status.idle":"2024-05-25T03:52:45.729017Z","shell.execute_reply.started":"2024-05-25T03:52:44.701647Z","shell.execute_reply":"2024-05-25T03:52:45.728074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the top 3 pages that are likely to contain the topic of interest\nsearch_score, search_index = sentence_index.search(prompt_embeddings, 3)","metadata":{"papermill":{"duration":23.339585,"end_time":"2023-08-14T10:11:55.247556","exception":false,"start_time":"2023-08-14T10:11:31.907971","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:52:45.730144Z","iopub.execute_input":"2024-05-25T03:52:45.730450Z","iopub.status.idle":"2024-05-25T03:53:09.154722Z","shell.execute_reply.started":"2024-05-25T03:52:45.730425Z","shell.execute_reply":"2024-05-25T03:53:09.153791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Save memory - delete sentence_index since it is no longer necessary\ndel sentence_index\ndel prompt_embeddings\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"papermill":{"duration":0.877305,"end_time":"2023-08-14T10:11:56.145444","exception":false,"start_time":"2023-08-14T10:11:55.268139","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:53:09.160271Z","iopub.execute_input":"2024-05-25T03:53:09.162540Z","iopub.status.idle":"2024-05-25T03:53:10.042236Z","shell.execute_reply.started":"2024-05-25T03:53:09.162503Z","shell.execute_reply":"2024-05-25T03:53:10.041255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting Sentences from the Relevant Titles","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\",\n                     columns=['id', 'file'])","metadata":{"papermill":{"duration":5.737408,"end_time":"2023-08-14T10:12:01.897408","exception":false,"start_time":"2023-08-14T10:11:56.16","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:53:10.043863Z","iopub.execute_input":"2024-05-25T03:53:10.044302Z","iopub.status.idle":"2024-05-25T03:53:14.006371Z","shell.execute_reply.started":"2024-05-25T03:53:10.044265Z","shell.execute_reply":"2024-05-25T03:53:14.005485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the article and associated file location using the index\nwikipedia_file_data = []\n\nfor i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n    scr_idx = idx\n    _df = df.loc[scr_idx].copy()\n    _df['prompt_id'] = i\n    wikipedia_file_data.append(_df)\nwikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\nwikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)\n\n## Save memory - delete df since it is no longer necessary\ndel df\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"papermill":{"duration":0.799872,"end_time":"2023-08-14T10:12:02.712752","exception":false,"start_time":"2023-08-14T10:12:01.91288","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:53:14.007501Z","iopub.execute_input":"2024-05-25T03:53:14.007799Z","iopub.status.idle":"2024-05-25T03:53:14.743690Z","shell.execute_reply.started":"2024-05-25T03:53:14.007774Z","shell.execute_reply":"2024-05-25T03:53:14.742761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get the full text data\nwiki_text_data = []\n\nfor file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n    _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data['file']==file]['id'].tolist()]\n    _df = pd.read_parquet(f\"{WIKI_PATH}/{file}\", columns=['id', 'text'])\n\n    _df_temp = _df[_df['id'].isin(_id)].copy()\n    del _df\n    _ = gc.collect()\n    libc.malloc_trim(0)\n    wiki_text_data.append(_df_temp)\nwiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)\n_ = gc.collect()","metadata":{"papermill":{"duration":303.981049,"end_time":"2023-08-14T10:17:06.710072","exception":false,"start_time":"2023-08-14T10:12:02.729023","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:53:14.744843Z","iopub.execute_input":"2024-05-25T03:53:14.745168Z","iopub.status.idle":"2024-05-25T03:57:17.373510Z","shell.execute_reply.started":"2024-05-25T03:53:14.745143Z","shell.execute_reply":"2024-05-25T03:57:17.372465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Parse documents into sentences\nprocessed_wiki_text_data = process_documents(wiki_text_data.text.values, wiki_text_data.id.values)","metadata":{"papermill":{"duration":4.491281,"end_time":"2023-08-14T10:17:11.220342","exception":false,"start_time":"2023-08-14T10:17:06.729061","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:57:17.374863Z","iopub.execute_input":"2024-05-25T03:57:17.375279Z","iopub.status.idle":"2024-05-25T03:57:23.810393Z","shell.execute_reply.started":"2024-05-25T03:57:17.375244Z","shell.execute_reply":"2024-05-25T03:57:23.809376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get embeddings of the wiki text data\nwiki_data_embeddings = model.encode(processed_wiki_text_data.text,\n                                    batch_size=BATCH_SIZE,\n                                    device=DEVICE,\n                                    show_progress_bar=True,\n                                    convert_to_tensor=True,\n                                    normalize_embeddings=True)#.half()\nwiki_data_embeddings = wiki_data_embeddings.detach().cpu().numpy()","metadata":{"papermill":{"duration":25.110593,"end_time":"2023-08-14T10:17:36.348422","exception":false,"start_time":"2023-08-14T10:17:11.237829","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:57:23.811554Z","iopub.execute_input":"2024-05-25T03:57:23.811856Z","iopub.status.idle":"2024-05-25T03:57:56.222664Z","shell.execute_reply.started":"2024-05-25T03:57:23.811832Z","shell.execute_reply":"2024-05-25T03:57:56.221782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = gc.collect()","metadata":{"papermill":{"duration":0.315807,"end_time":"2023-08-14T10:17:36.679867","exception":false,"start_time":"2023-08-14T10:17:36.36406","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:57:56.227256Z","iopub.execute_input":"2024-05-25T03:57:56.227566Z","iopub.status.idle":"2024-05-25T03:57:56.552524Z","shell.execute_reply.started":"2024-05-25T03:57:56.227538Z","shell.execute_reply":"2024-05-25T03:57:56.551369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Combine all answers\ntrn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\n\n\n## Search using the prompt and answers to guide the search\ntrn['prompt_answer_stem'] = trn['prompt'] + \" \" + trn['answer_all']","metadata":{"papermill":{"duration":0.034767,"end_time":"2023-08-14T10:17:36.730378","exception":false,"start_time":"2023-08-14T10:17:36.695611","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:57:56.553814Z","iopub.execute_input":"2024-05-25T03:57:56.554184Z","iopub.status.idle":"2024-05-25T03:57:56.570668Z","shell.execute_reply.started":"2024-05-25T03:57:56.554143Z","shell.execute_reply":"2024-05-25T03:57:56.569833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question_embeddings = model.encode(trn.prompt_answer_stem.values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nquestion_embeddings = question_embeddings.detach().cpu().numpy()","metadata":{"papermill":{"duration":0.431343,"end_time":"2023-08-14T10:17:37.177862","exception":false,"start_time":"2023-08-14T10:17:36.746519","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:57:56.571903Z","iopub.execute_input":"2024-05-25T03:57:56.572198Z","iopub.status.idle":"2024-05-25T03:57:56.894143Z","shell.execute_reply.started":"2024-05-25T03:57:56.572173Z","shell.execute_reply":"2024-05-25T03:57:56.893215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Matching Prompt-Sentence Pairs","metadata":{}},{"cell_type":"code","source":"## Parameter to determine how many relevant sentences to include\nNUM_SENTENCES_INCLUDE = 20\n\n## List containing just Context\ncontexts = []\n\nfor r in tqdm(trn.itertuples(), total=len(trn)):\n\n    prompt_id = r.Index\n\n    prompt_indices = processed_wiki_text_data[processed_wiki_text_data['document_id'].isin(wikipedia_file_data[wikipedia_file_data['prompt_id']==prompt_id]['id'].values)].index.values\n\n    if prompt_indices.shape[0] > 0:\n        prompt_index = faiss.index_factory(wiki_data_embeddings.shape[1], \"Flat\")\n        prompt_index.add(wiki_data_embeddings[prompt_indices])\n\n        context = \"\"\n        \n        ## Get the top matches\n        ss, ii = prompt_index.search(question_embeddings, NUM_SENTENCES_INCLUDE)\n        for _s, _i in zip(ss[prompt_id], ii[prompt_id]):\n            context += processed_wiki_text_data.loc[prompt_indices]['text'].iloc[_i] + \" \"\n        \n    contexts.append(context)","metadata":{"papermill":{"duration":1.609553,"end_time":"2023-08-14T10:17:38.836268","exception":false,"start_time":"2023-08-14T10:17:37.226715","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:57:56.895507Z","iopub.execute_input":"2024-05-25T03:57:56.895877Z","iopub.status.idle":"2024-05-25T03:58:00.465088Z","shell.execute_reply.started":"2024-05-25T03:57:56.895842Z","shell.execute_reply":"2024-05-25T03:58:00.464298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn['context'] = contexts","metadata":{"papermill":{"duration":0.024188,"end_time":"2023-08-14T10:17:38.878394","exception":false,"start_time":"2023-08-14T10:17:38.854206","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:58:00.466264Z","iopub.execute_input":"2024-05-25T03:58:00.466752Z","iopub.status.idle":"2024-05-25T03:58:00.471023Z","shell.execute_reply.started":"2024-05-25T03:58:00.466714Z","shell.execute_reply":"2024-05-25T03:58:00.470370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn[[\"prompt\", \"context\", \"A\", \"B\", \"C\", \"D\", \"E\"]].to_csv(\"./test_context.csv\", index=False)","metadata":{"papermill":{"duration":0.050945,"end_time":"2023-08-14T10:17:38.944423","exception":false,"start_time":"2023-08-14T10:17:38.893478","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:58:00.472215Z","iopub.execute_input":"2024-05-25T03:58:00.472621Z","iopub.status.idle":"2024-05-25T03:58:00.537934Z","shell.execute_reply.started":"2024-05-25T03:58:00.472597Z","shell.execute_reply":"2024-05-25T03:58:00.537111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"papermill":{"duration":0.015828,"end_time":"2023-08-14T10:17:39.007683","exception":false,"start_time":"2023-08-14T10:17:38.991855","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_df = pd.read_csv(\"test_context.csv\")\ntest_df.index = list(range(len(test_df)))\ntest_df['id'] = list(range(len(test_df)))\ntest_df[\"prompt\"] = test_df[\"context\"].apply(lambda x: x[:1750]) + \" #### \" +  test_df[\"prompt\"]\ntest_df['answer'] = 'A'","metadata":{"papermill":{"duration":0.037633,"end_time":"2023-08-14T10:17:39.605345","exception":false,"start_time":"2023-08-14T10:17:39.567712","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:58:00.539118Z","iopub.execute_input":"2024-05-25T03:58:00.539417Z","iopub.status.idle":"2024-05-25T03:58:00.566879Z","shell.execute_reply.started":"2024-05-25T03:58:00.539392Z","shell.execute_reply":"2024-05-25T03:58:00.566040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = \"/kaggle/input/llm-science-model/model_v2\"\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\nmodel.eval()","metadata":{"papermill":{"duration":21.360878,"end_time":"2023-08-14T10:18:01.027859","exception":false,"start_time":"2023-08-14T10:17:39.666981","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:58:00.568065Z","iopub.execute_input":"2024-05-25T03:58:00.568390Z","iopub.status.idle":"2024-05-25T03:58:16.677844Z","shell.execute_reply.started":"2024-05-25T03:58:00.568362Z","shell.execute_reply":"2024-05-25T03:58:16.676954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\noptions = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(example):\n    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n    # so we'll copy our question 5 times before tokenizing\n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    # Our tokenizer will turn our text into token IDs BERT can understand\n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example","metadata":{"papermill":{"duration":0.026162,"end_time":"2023-08-14T10:18:01.129276","exception":false,"start_time":"2023-08-14T10:18:01.103114","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:58:16.678828Z","iopub.execute_input":"2024-05-25T03:58:16.679094Z","iopub.status.idle":"2024-05-25T03:58:16.685860Z","shell.execute_reply.started":"2024-05-25T03:58:16.679071Z","shell.execute_reply":"2024-05-25T03:58:16.685041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"papermill":{"duration":0.030447,"end_time":"2023-08-14T10:18:01.175589","exception":false,"start_time":"2023-08-14T10:18:01.145142","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:58:16.686974Z","iopub.execute_input":"2024-05-25T03:58:16.687298Z","iopub.status.idle":"2024-05-25T03:58:16.702703Z","shell.execute_reply.started":"2024-05-25T03:58:16.687257Z","shell.execute_reply":"2024-05-25T03:58:16.701931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_dataset = Dataset.from_pandas(test_df[['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer']].drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_test_dataset = tokenized_test_dataset.remove_columns([\"__index_level_0__\"])\ndata_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\ntest_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, shuffle=False, collate_fn=data_collator)","metadata":{"papermill":{"duration":0.493618,"end_time":"2023-08-14T10:18:01.685989","exception":false,"start_time":"2023-08-14T10:18:01.192371","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:58:16.704148Z","iopub.execute_input":"2024-05-25T03:58:16.704583Z","iopub.status.idle":"2024-05-25T03:58:17.866212Z","shell.execute_reply.started":"2024-05-25T03:58:16.704506Z","shell.execute_reply":"2024-05-25T03:58:17.865434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = []\nfor batch in test_dataloader:\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    test_predictions.append(outputs.logits.cpu().detach())\n\ntest_predictions = torch.cat(test_predictions)\ntest_predictions = test_predictions.numpy()","metadata":{"papermill":{"duration":1.101895,"end_time":"2023-08-14T10:18:02.804298","exception":false,"start_time":"2023-08-14T10:18:01.702403","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T03:58:17.867330Z","iopub.execute_input":"2024-05-25T03:58:17.867607Z","iopub.status.idle":"2024-05-25T03:59:26.329802Z","shell.execute_reply.started":"2024-05-25T03:58:17.867581Z","shell.execute_reply":"2024-05-25T03:59:26.328987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model From Our Train Notebook","metadata":{}},{"cell_type":"code","source":"model_dir = \"/kaggle/input/llm-science-model/model_v2\"\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T03:59:26.331124Z","iopub.execute_input":"2024-05-25T03:59:26.331479Z","iopub.status.idle":"2024-05-25T03:59:31.061037Z","shell.execute_reply.started":"2024-05-25T03:59:26.331446Z","shell.execute_reply":"2024-05-25T03:59:31.060084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions2 = []\nfor batch in test_dataloader:\n    for k in batch.keys():\n        batch[k] = batch[k].cuda()\n    with torch.no_grad():\n        outputs = model(**batch)\n    test_predictions2.append(outputs.logits.cpu().detach())\n\ntest_predictions2 = torch.cat(test_predictions2)\ntest_predictions = (test_predictions+test_predictions2.numpy()) / 2.0\n\npredictions_as_ids = np.argsort(-test_predictions, 1)\n\npredictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n# predictions_as_answer_letters[:3]\n\npredictions_as_string = test_df['prediction'] = [\n    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T03:59:31.062351Z","iopub.execute_input":"2024-05-25T03:59:31.062708Z","iopub.status.idle":"2024-05-25T04:00:39.250880Z","shell.execute_reply.started":"2024-05-25T03:59:31.062675Z","shell.execute_reply":"2024-05-25T04:00:39.249861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_df[['id', 'prediction']]\nsubmission.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.033576,"end_time":"2023-08-14T10:19:17.733491","exception":false,"start_time":"2023-08-14T10:19:17.699915","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-25T04:00:39.252039Z","iopub.execute_input":"2024-05-25T04:00:39.252378Z","iopub.status.idle":"2024-05-25T04:00:39.260607Z","shell.execute_reply.started":"2024-05-25T04:00:39.252349Z","shell.execute_reply":"2024-05-25T04:00:39.259604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}