{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":3680037,"sourceType":"datasetVersion","datasetId":2202288},{"sourceId":4988409,"sourceType":"datasetVersion","datasetId":2893282},{"sourceId":6146260,"sourceType":"datasetVersion","datasetId":3521629},{"sourceId":6146317,"sourceType":"datasetVersion","datasetId":3524699},{"sourceId":6149251,"sourceType":"datasetVersion","datasetId":3526632},{"sourceId":6149280,"sourceType":"datasetVersion","datasetId":3526656},{"sourceId":6175087,"sourceType":"datasetVersion","datasetId":3540289},{"sourceId":6278879,"sourceType":"datasetVersion","datasetId":3609974},{"sourceId":6287559,"sourceType":"datasetVersion","datasetId":3615797},{"sourceId":6312508,"sourceType":"datasetVersion","datasetId":3631952},{"sourceId":6315195,"sourceType":"datasetVersion","datasetId":3626780},{"sourceId":6363321,"sourceType":"datasetVersion","datasetId":3638263}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U /kaggle/input/faiss-cpu-173/faiss_cpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T05:25:55.358200Z","iopub.execute_input":"2024-05-22T05:25:55.358563Z","iopub.status.idle":"2024-05-22T05:26:10.700091Z","shell.execute_reply.started":"2024-05-22T05:25:55.358534Z","shell.execute_reply":"2024-05-22T05:26:10.699035Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/faiss-cpu-173/faiss_cpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.7.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"FAISS (Facebook AI Similarity Search) is a library developed by Facebook AI Research, designed for efficient similarity search and clustering of dense vectors. we install it from dataset cuz in submission internet is turned off.","metadata":{}},{"cell_type":"code","source":"!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:10.702708Z","iopub.execute_input":"2024-05-22T05:26:10.703147Z","iopub.status.idle":"2024-05-22T05:26:14.692243Z","shell.execute_reply.started":"2024-05-22T05:26:10.703106Z","shell.execute_reply":"2024-05-22T05:26:14.690784Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"The command copies the entire sentence-transformers directory (including all its contents) from the input directory (/kaggle/input/sentence-transformers-222) to the working directory (/kaggle/working). This is often done to make the files accessible for further processing or usage within the notebook, as the /kaggle/working directory is writable and intended for active work during the notebook session. Python library designed for computing dense vector representations for sentences, paragraphs, and images","metadata":{}},{"cell_type":"code","source":"!pip install -U /kaggle/working/sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:14.693825Z","iopub.execute_input":"2024-05-22T05:26:14.694178Z","iopub.status.idle":"2024-05-22T05:26:31.552760Z","shell.execute_reply.started":"2024-05-22T05:26:14.694147Z","shell.execute_reply":"2024-05-22T05:26:31.551609Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Processing ./sentence-transformers\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.16.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.2.0)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126117 sha256=cd69a547974a2108be33f913e8032fdbca869b4f36ef7af0f448f1d103efc65a\n  Stored in directory: /root/.cache/pip/wheels/6c/ea/76/d9a930b223b1d3d5d6aff69458725316b0fe205b854faf1812\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:31.555314Z","iopub.execute_input":"2024-05-22T05:26:31.555655Z","iopub.status.idle":"2024-05-22T05:26:46.206176Z","shell.execute_reply.started":"2024-05-22T05:26:31.555626Z","shell.execute_reply":"2024-05-22T05:26:46.204977Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\nInstalling collected packages: blingfire\nSuccessfully installed blingfire-0.1.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:46.207900Z","iopub.execute_input":"2024-05-22T05:26:46.208337Z","iopub.status.idle":"2024-05-22T05:26:46.213982Z","shell.execute_reply.started":"2024-05-22T05:26:46.208295Z","shell.execute_reply":"2024-05-22T05:26:46.212917Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm.auto import tqdm\nimport blingfire as bf\nimport torch\n\nfrom collections.abc import Iterable\n\nimport faiss\nfrom faiss import write_index, read_index\n\nfrom sentence_transformers import SentenceTransformer","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:46.215458Z","iopub.execute_input":"2024-05-22T05:26:46.215753Z","iopub.status.idle":"2024-05-22T05:26:53.873675Z","shell.execute_reply.started":"2024-05-22T05:26:46.215730Z","shell.execute_reply":"2024-05-22T05:26:53.872780Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\nDEVICE = 0\nMAX_LENGTH = 384\nBATCH_SIZE = 16","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:53.874988Z","iopub.execute_input":"2024-05-22T05:26:53.876100Z","iopub.status.idle":"2024-05-22T05:26:53.880773Z","shell.execute_reply.started":"2024-05-22T05:26:53.876073Z","shell.execute_reply":"2024-05-22T05:26:53.879814Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda'\n    print(\"CUDA is available. Using GPU.\")\nelse:\n    device = 'cpu'\n    print(\"CUDA is not available. Using CPU.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:53.882346Z","iopub.execute_input":"2024-05-22T05:26:53.882710Z","iopub.status.idle":"2024-05-22T05:26:54.062649Z","shell.execute_reply.started":"2024-05-22T05:26:53.882666Z","shell.execute_reply":"2024-05-22T05:26:54.061618Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"CUDA is available. Using GPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"WIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(WIKI_PATH) #directory list of wikipedia dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:39:06.710944Z","iopub.execute_input":"2024-05-22T05:39:06.711826Z","iopub.status.idle":"2024-05-22T05:39:06.717557Z","shell.execute_reply.started":"2024-05-22T05:39:06.711794Z","shell.execute_reply":"2024-05-22T05:39:06.716522Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"trn = pd.read_csv(\"/kaggle/input/llm-science-exam-sciq-dataset/test_sciq.csv\")\ntrn = trn.dropna()\ntrn","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:39:07.063243Z","iopub.execute_input":"2024-05-22T05:39:07.064034Z","iopub.status.idle":"2024-05-22T05:39:07.082755Z","shell.execute_reply.started":"2024-05-22T05:39:07.064001Z","shell.execute_reply":"2024-05-22T05:39:07.081871Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [id, prompt, D, E, A, C, B, answer]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>D</th>\n      <th>E</th>\n      <th>A</th>\n      <th>C</th>\n      <th>B</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# Sample dataframes (trn1, trn2, ..., trn9) are assumed to be defined already\n\n# Concatenate all dataframes\ntrn_merged = pd.concat([trn1, trn2, trn3, trn4, trn5, trn6, trn7, trn8, trn9], ignore_index=True, sort=False)\n\n# Drop rows with any NaN values\ntrn_merged = trn_merged.dropna()\ntrn_merged.reset_index(inplace=True)\n\n# Drop the existing 'id' column if it exists\nif 'id' in trn_merged.columns:\n    trn_merged = trn_merged.drop('id', axis=1)\n    trn_merged = trn_merged.drop('index', axis=1)\n\ntrn_merged['id'] = np.arange(len(trn_merged))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:15:03.790127Z","iopub.execute_input":"2024-05-21T12:15:03.790567Z","iopub.status.idle":"2024-05-21T12:15:03.852994Z","shell.execute_reply.started":"2024-05-21T12:15:03.790536Z","shell.execute_reply":"2024-05-21T12:15:03.851975Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"trn = trn_merged\ntrn","metadata":{"execution":{"iopub.status.busy":"2024-05-21T12:15:05.468107Z","iopub.execute_input":"2024-05-21T12:15:05.468495Z","iopub.status.idle":"2024-05-21T12:15:05.484033Z","shell.execute_reply.started":"2024-05-21T12:15:05.468464Z","shell.execute_reply":"2024-05-21T12:15:05.483147Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                 prompt  \\\n0     Which of the following statements accurately d...   \n1     Which of the following is an accurate definiti...   \n2     Which of the following statements accurately d...   \n3     What is the significance of regularization in ...   \n4     Which of the following statements accurately d...   \n...                                                 ...   \n6815  What are the ownership advantages of a proprie...   \n6816  How may proprietors enforce restrictions on a ...   \n6817      What is an example of a proprietary protocol?   \n6818  What is the process of retrieving a protocol's...   \n6819  Who is the author of \"The Question Concerning ...   \n\n                                                      A  \\\n0     MOND is a theory that reduces the observed mis...   \n1     Dynamic scaling refers to the evolution of sel...   \n2     The triskeles symbol was reconstructed as a fe...   \n3     Regularizing the mass-energy of an electron wi...   \n4     The angular spacing of features in the diffrac...   \n...                                                 ...   \n6815  Ability to restrict use of the protocol and ch...   \n6816  By controlling intellectual property rights an...   \n6817                                             TCP/IP   \n6818                                      Decompilation   \n6819                                Friedrich Nietzsche   \n\n                                                      B  \\\n0     MOND is a theory that increases the discrepanc...   \n1     Dynamic scaling refers to the non-evolution of...   \n2     The triskeles symbol is a representation of th...   \n3     Regularizing the mass-energy of an electron wi...   \n4     The angular spacing of features in the diffrac...   \n...                                                 ...   \n6815       Ability to freely distribute implementations   \n6816             By widely distributing implementations   \n6817                                               HTTP   \n6818                                    Packet sniffing   \n6819                                      Immanuel Kant   \n\n                                                      C  \\\n0     MOND is a theory that explains the missing bar...   \n1     Dynamic scaling refers to the evolution of sel...   \n2     The triskeles symbol is a representation of a ...   \n3     Regularizing the mass-energy of an electron wi...   \n4     The angular spacing of features in the diffrac...   \n...                                                 ...   \n6815                   Ability to enforce patent rights   \n6816    By freely publishing the protocol specification   \n6817                                     Skype protocol   \n6818                                 Binary disassembly   \n6819                                   Martin Heidegger   \n\n                                                      D  \\\n0     MOND is a theory that reduces the discrepancy ...   \n1     Dynamic scaling refers to the non-evolution of...   \n2     The triskeles symbol represents three interloc...   \n3     Regularizing the mass-energy of an electron wi...   \n4     The angular spacing of features in the diffrac...   \n...                                                 ...   \n6815        Ability to make the protocol a trade secret   \n6816     By allowing anyone to create an implementation   \n6817                                               SMTP   \n6818                                Reverse engineering   \n6819                                      Sigmund Freud   \n\n                                                      E answer    id  \n0     MOND is a theory that eliminates the observed ...      D     0  \n1     Dynamic scaling refers to the evolution of sel...      A     1  \n2     The triskeles symbol is a representation of th...      A     2  \n3     Regularizing the mass-energy of an electron wi...      C     3  \n4     The angular spacing of features in the diffrac...      D     4  \n...                                                 ...    ...   ...  \n6815  Ability to freely publish the protocol specifi...      A  6815  \n6816              By making the protocol a trade secret      A  6816  \n6817                                                FTP      C  6817  \n6818                                Protocol extraction      D  6818  \n6819                                Arthur Schopenhauer      C  6819  \n\n[6820 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n      <td>D</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>A</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>A</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>C</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>D</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6815</th>\n      <td>What are the ownership advantages of a proprie...</td>\n      <td>Ability to restrict use of the protocol and ch...</td>\n      <td>Ability to freely distribute implementations</td>\n      <td>Ability to enforce patent rights</td>\n      <td>Ability to make the protocol a trade secret</td>\n      <td>Ability to freely publish the protocol specifi...</td>\n      <td>A</td>\n      <td>6815</td>\n    </tr>\n    <tr>\n      <th>6816</th>\n      <td>How may proprietors enforce restrictions on a ...</td>\n      <td>By controlling intellectual property rights an...</td>\n      <td>By widely distributing implementations</td>\n      <td>By freely publishing the protocol specification</td>\n      <td>By allowing anyone to create an implementation</td>\n      <td>By making the protocol a trade secret</td>\n      <td>A</td>\n      <td>6816</td>\n    </tr>\n    <tr>\n      <th>6817</th>\n      <td>What is an example of a proprietary protocol?</td>\n      <td>TCP/IP</td>\n      <td>HTTP</td>\n      <td>Skype protocol</td>\n      <td>SMTP</td>\n      <td>FTP</td>\n      <td>C</td>\n      <td>6817</td>\n    </tr>\n    <tr>\n      <th>6818</th>\n      <td>What is the process of retrieving a protocol's...</td>\n      <td>Decompilation</td>\n      <td>Packet sniffing</td>\n      <td>Binary disassembly</td>\n      <td>Reverse engineering</td>\n      <td>Protocol extraction</td>\n      <td>D</td>\n      <td>6818</td>\n    </tr>\n    <tr>\n      <th>6819</th>\n      <td>Who is the author of \"The Question Concerning ...</td>\n      <td>Friedrich Nietzsche</td>\n      <td>Immanuel Kant</td>\n      <td>Martin Heidegger</td>\n      <td>Sigmund Freud</td>\n      <td>Arthur Schopenhauer</td>\n      <td>C</td>\n      <td>6819</td>\n    </tr>\n  </tbody>\n</table>\n<p>6820 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model = SentenceTransformer(MODEL, device=device)\nmodel.max_seq_length = MAX_LENGTH\nmodel = model.half()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:27:06.631331Z","iopub.execute_input":"2024-05-22T05:27:06.631709Z","iopub.status.idle":"2024-05-22T05:27:08.829283Z","shell.execute_reply.started":"2024-05-22T05:27:06.631679Z","shell.execute_reply":"2024-05-22T05:27:08.828272Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"sentence_index = read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:27:08.833663Z","iopub.execute_input":"2024-05-22T05:27:08.834542Z","iopub.status.idle":"2024-05-22T05:28:13.792024Z","shell.execute_reply.started":"2024-05-22T05:27:08.834508Z","shell.execute_reply":"2024-05-22T05:28:13.790925Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"prompt_embeddings = model.encode(trn.prompt.values, batch_size=BATCH_SIZE, device=device, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True).half()\nprompt_embeddings = prompt_embeddings.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:13.793426Z","iopub.execute_input":"2024-05-22T05:28:13.793733Z","iopub.status.idle":"2024-05-22T05:28:15.225405Z","shell.execute_reply.started":"2024-05-22T05:28:13.793708Z","shell.execute_reply":"2024-05-22T05:28:15.224605Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c783b4b21af4475c9b7c47eb24d44de4"}},"metadata":{}}]},{"cell_type":"code","source":"_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:15.228285Z","iopub.execute_input":"2024-05-22T05:28:15.228679Z","iopub.status.idle":"2024-05-22T05:28:15.423677Z","shell.execute_reply.started":"2024-05-22T05:28:15.228646Z","shell.execute_reply":"2024-05-22T05:28:15.422610Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"## Get the top 3 pages that are likely to contain the topic of interest\nsearch_score, search_index = sentence_index.search(prompt_embeddings, 3)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:15.424945Z","iopub.execute_input":"2024-05-22T05:28:15.425300Z","iopub.status.idle":"2024-05-22T05:28:42.741943Z","shell.execute_reply.started":"2024-05-22T05:28:15.425276Z","shell.execute_reply":"2024-05-22T05:28:42.740810Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"## Save memory - delete sentence_index since it is no longer necessary\ndel sentence_index\ndel prompt_embeddings\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:42.743791Z","iopub.execute_input":"2024-05-22T05:28:42.744213Z","iopub.status.idle":"2024-05-22T05:28:43.547798Z","shell.execute_reply.started":"2024-05-22T05:28:42.744174Z","shell.execute_reply":"2024-05-22T05:28:43.546535Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\", columns=['id', 'file'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:43.548885Z","iopub.execute_input":"2024-05-22T05:28:43.549239Z","iopub.status.idle":"2024-05-22T05:28:48.012361Z","shell.execute_reply.started":"2024-05-22T05:28:43.549212Z","shell.execute_reply":"2024-05-22T05:28:48.011230Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"         id       file\n0  49495844  a.parquet\n1   3579086  a.parquet\n2  62397582  a.parquet\n3  15547032  a.parquet\n4   8021609  a.parquet","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49495844</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3579086</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>62397582</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15547032</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8021609</td>\n      <td>a.parquet</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Get the article and associated file location using the index\nwikipedia_file_data = []\n\nfor i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n    \n    ## Get indices by score threshold\n    #scr_idx = idx[np.where(scr <= 0.85)]\n    scr_idx = idx\n    _df = df.loc[scr_idx].copy()\n    _df['prompt_id'] = i\n    wikipedia_file_data.append(_df)\nwikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\nwikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)\n\n## Save memory - delete df since it is no longer necessary\ndel df\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:48.013795Z","iopub.execute_input":"2024-05-22T05:28:48.014608Z","iopub.status.idle":"2024-05-22T05:28:49.210740Z","shell.execute_reply.started":"2024-05-22T05:28:48.014559Z","shell.execute_reply":"2024-05-22T05:28:49.209843Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ceef049815fa479fbb0bbdde17001eb1"}},"metadata":{}}]},{"cell_type":"code","source":"wikipedia_file_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:49.212055Z","iopub.execute_input":"2024-05-22T05:28:49.212516Z","iopub.status.idle":"2024-05-22T05:28:49.223868Z","shell.execute_reply.started":"2024-05-22T05:28:49.212482Z","shell.execute_reply":"2024-05-22T05:28:49.222812Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"         id  prompt_id       file\n0  10151726        582  a.parquet\n1   1044136        491  a.parquet\n2    106240        273  a.parquet\n3    106240        358  a.parquet\n4    106240        442  a.parquet","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10151726</td>\n      <td>582</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1044136</td>\n      <td>491</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>106240</td>\n      <td>273</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>106240</td>\n      <td>358</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>106240</td>\n      <td>442</td>\n      <td>a.parquet</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Get the full text data\nwiki_text_data = []\n\nfor file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n    _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data['file']==file]['id'].tolist()]\n    _df = pd.read_parquet(f\"{WIKI_PATH}/{file}\", columns=['id', 'text'])\n\n    _df = _df[_df['id'].isin(_id)]\n    wiki_text_data.append(_df)\n    _ = gc.collect()\nwiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:49.227627Z","iopub.execute_input":"2024-05-22T05:28:49.227916Z","iopub.status.idle":"2024-05-22T05:33:31.598304Z","shell.execute_reply.started":"2024-05-22T05:28:49.227893Z","shell.execute_reply":"2024-05-22T05:33:31.597436Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/27 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78fe36942ea64d6b953ab211b38e8dc3"}},"metadata":{}}]},{"cell_type":"code","source":"wiki_text_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:33:31.599378Z","iopub.execute_input":"2024-05-22T05:33:31.599648Z","iopub.status.idle":"2024-05-22T05:33:31.609774Z","shell.execute_reply.started":"2024-05-22T05:33:31.599627Z","shell.execute_reply":"2024-05-22T05:33:31.608756Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"         id                                               text\n0  45502742  AC/DC is a pinball machine manufactured by Ste...\n1   4362284  AC/DC for General Exhibition, released only in...\n2   2225115  AC/DC Live is the second live album by Austral...\n3   1665285  In biology and ecology, abiotic components or ...\n4    571480  Absorbed dose is a dose quantity which is the ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>45502742</td>\n      <td>AC/DC is a pinball machine manufactured by Ste...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4362284</td>\n      <td>AC/DC for General Exhibition, released only in...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2225115</td>\n      <td>AC/DC Live is the second live album by Austral...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1665285</td>\n      <td>In biology and ecology, abiotic components or ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>571480</td>\n      <td>Absorbed dose is a dose quantity which is the ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"text_to_sentences_and_offsets function from the Bling Fire library (blingfire) to tokenize a document into sentences and obtain their character offsets within the original document","metadata":{}},{"cell_type":"code","source":"def process_documents(documents: Iterable[str],\n                      document_ids: Iterable,\n                      split_sentences: bool = True,\n                      filter_len: int = 3,\n                      disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Main helper function to process documents from the EMR.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param document_type: String denoting the document type to be processed\n    :param document_sections: List of sections for a given document type to process\n    :param split_sentences: Flag to determine whether to further split sections into sentences\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n    \n    df = sectionize_documents(documents, document_ids, disable_progress_bar)\n    print(df.head())\n    if split_sentences:\n        df = sentencize(df.text.values, \n                        df.document_id.values,\n                        df.offset.values, \n                        filter_len, \n                        disable_progress_bar)\n    print(df.head())\n    return df\n\n\ndef sectionize_documents(documents: Iterable[str],\n                         document_ids: Iterable,\n                         disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Obtains the sections of the imaging reports and returns only the \n    selected sections (defaults to FINDINGS, IMPRESSION, and ADDENDUM).\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param disable_progress_bar: Flag to disable tqdm progress bar\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `offset`\n    \"\"\"\n    processed_documents = []\n    for document_id, document in tqdm(zip(document_ids, documents), total=len(documents), disable=disable_progress_bar):\n        row = {}\n        text, start, end = (document, 0, len(document))\n        row['document_id'] = document_id\n        row['text'] = text\n        row['offset'] = (start, end)\n\n        processed_documents.append(row)\n\n    _df = pd.DataFrame(processed_documents)\n    if _df.shape[0] > 0:\n        return _df.sort_values(['document_id', 'offset']).reset_index(drop=True)\n    else:\n        return _df\n\n\ndef sentencize(documents: Iterable[str],\n               document_ids: Iterable,\n               offsets: Iterable[tuple[int, int]],\n               filter_len: int = 3,\n               disable_progress_bar: bool = False) -> pd.DataFrame:\n    \"\"\"\n    Split a document into sentences. Can be used with `sectionize_documents`\n    to further split documents into more manageable pieces. Takes in offsets\n    to ensure that after splitting, the sentences can be matched to the\n    location in the original documents.\n\n    :param documents: Iterable containing documents which are strings\n    :param document_ids: Iterable containing document unique identifiers\n    :param offsets: Iterable tuple of the start and end indices\n    :param filter_len: Minimum character length of a sentence (otherwise filter out)\n    :return: Pandas DataFrame containing the columns `document_id`, `text`, `section`, `offset`\n    \"\"\"\n\n    document_sentences = []\n    for document, document_id, offset in tqdm(zip(documents, document_ids, offsets), total=len(documents), disable=disable_progress_bar):\n        try:\n            _, sentence_offsets = bf.text_to_sentences_and_offsets(document)\n            for o in sentence_offsets:\n                if o[1]-o[0] > filter_len:\n                    sentence = document[o[0]:o[1]]\n                    abs_offsets = (o[0]+offset[0], o[1]+offset[0])\n                    row = {}\n                    row['document_id'] = document_id\n                    row['text'] = sentence\n                    row['offset'] = abs_offsets\n                    document_sentences.append(row)\n        except:\n            continue\n    return pd.DataFrame(document_sentences)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:33:31.611527Z","iopub.execute_input":"2024-05-22T05:33:31.611805Z","iopub.status.idle":"2024-05-22T05:33:31.628786Z","shell.execute_reply.started":"2024-05-22T05:33:31.611782Z","shell.execute_reply":"2024-05-22T05:33:31.627839Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"## Parse documents into sentences\nprocessed_wiki_text_data = process_documents(wiki_text_data.text.values, wiki_text_data.id.values)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:33:31.629995Z","iopub.execute_input":"2024-05-22T05:33:31.630324Z","iopub.status.idle":"2024-05-22T05:33:51.073342Z","shell.execute_reply.started":"2024-05-22T05:33:31.630295Z","shell.execute_reply":"2024-05-22T05:33:51.072177Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2519 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0569c71456974aecba7ea1c24a73db99"}},"metadata":{}},{"name":"stdout","text":"  document_id                                               text      offset\n0       10008  An electrode is an electrical conductor used t...  (0, 23681)\n1    10013669  In evolutionary biology, function is the reaso...   (0, 6585)\n2       10065  In chemistry, the empirical formula of a chemi...   (0, 3299)\n3    10085128  The following is a list of the classes in each...   (0, 4436)\n4    10085290  Lyme disease, or borreliosis, is caused by spi...  (0, 16135)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2519 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd212ec1dede45449e1f752cf963a9c4"}},"metadata":{}},{"name":"stdout","text":"  document_id                                               text      offset\n0       10008  An electrode is an electrical conductor used t...    (0, 154)\n1       10008  Electrodes are essential parts of batteries th...  (155, 275)\n2       10008  The electrophore, invented by Johan Wilcke, wa...  (276, 488)\n3       10008  The first electrochemical battery made was dev...  (489, 610)\n4       10008  Biography of Alessandro Volta – Stored Electri...  (611, 684)\n","output_type":"stream"}]},{"cell_type":"code","source":"## Get embeddings of the wiki text data\nwiki_data_embeddings = model.encode(processed_wiki_text_data.text, batch_size=BATCH_SIZE, device=device, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True).half()\nwiki_data_embeddings = wiki_data_embeddings.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:33:51.074675Z","iopub.execute_input":"2024-05-22T05:33:51.075033Z","iopub.status.idle":"2024-05-22T05:35:25.664320Z","shell.execute_reply.started":"2024-05-22T05:33:51.075001Z","shell.execute_reply":"2024-05-22T05:35:25.663359Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/9695 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd248fdeae9040bc8875626b4ab2ace5"}},"metadata":{}}]},{"cell_type":"code","source":"wiki_data_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:35:25.665503Z","iopub.execute_input":"2024-05-22T05:35:25.665872Z","iopub.status.idle":"2024-05-22T05:35:25.673310Z","shell.execute_reply.started":"2024-05-22T05:35:25.665841Z","shell.execute_reply":"2024-05-22T05:35:25.672149Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"array([[-0.0399   ,  0.0648   ,  0.04544  , ...,  0.05402  ,  0.036    ,\n         0.03165  ],\n       [-0.0437   ,  0.07904  ,  0.04007  , ...,  0.05795  ,  0.0871   ,\n         0.00616  ],\n       [-0.03647  ,  0.133    ,  0.0257   , ...,  0.0654   ,  0.08185  ,\n         0.03723  ],\n       ...,\n       [ 0.0365   ,  0.01442  ,  0.063    , ...,  0.0003355, -0.1098   ,\n        -0.04132  ],\n       [-0.00284  ,  0.01915  ,  0.02888  , ..., -0.02487  , -0.05255  ,\n        -0.04794  ],\n       [ 0.02475  , -0.008934 ,  0.0827   , ...,  0.01822  , -0.07684  ,\n        -0.01229  ]], dtype=float16)"},"metadata":{}}]},{"cell_type":"code","source":"_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:35:25.674522Z","iopub.execute_input":"2024-05-22T05:35:25.674879Z","iopub.status.idle":"2024-05-22T05:35:25.874671Z","shell.execute_reply.started":"2024-05-22T05:35:25.674843Z","shell.execute_reply":"2024-05-22T05:35:25.873553Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"## Combine all answers\ntrn['answer_all'] = trn.apply(lambda x: \" \".join([x['A'], x['B'], x['C'], x['D'], x['E']]), axis=1)\n\n## Search using the prompt and answers to guide the search\ntrn['prompt_answer_stem'] = trn['prompt'] + \" \" + trn['answer_all']","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:35:25.875936Z","iopub.execute_input":"2024-05-22T05:35:25.876273Z","iopub.status.idle":"2024-05-22T05:35:27.357987Z","shell.execute_reply.started":"2024-05-22T05:35:25.876248Z","shell.execute_reply":"2024-05-22T05:35:27.356280Z"},"trusted":true},"execution_count":27,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Combine all answers\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_all\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## Search using the prompt and answers to guide the search\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_answer_stem\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m trn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m trn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_all\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Combine all answers\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_all\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m trn\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## Search using the prompt and answers to guide the search\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_answer_stem\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m trn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m trn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_all\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, float found"],"ename":"TypeError","evalue":"sequence item 0: expected str instance, float found","output_type":"error"}]},{"cell_type":"code","source":"question_embeddings = model.encode(trn.prompt_answer_stem.values, batch_size=BATCH_SIZE, device=device, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True).half()\nquestion_embeddings = question_embeddings.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:35:27.359434Z","iopub.status.idle":"2024-05-22T05:35:27.359832Z","shell.execute_reply.started":"2024-05-22T05:35:27.359629Z","shell.execute_reply":"2024-05-22T05:35:27.359645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Parameter to determine how many relevant sentences to include\nNUM_SENTENCES_INCLUDE = 3\n\n## List containing Question, Choices, Context\nprompt_contexts = []\n\n## List containing just Context\ncontexts = []\n\nfor r in trn.itertuples():\n    prompt_context = \"\"\n\n    prompt_id = r.id\n\n    prompt_indices = processed_wiki_text_data[processed_wiki_text_data['document_id'].isin(wikipedia_file_data[wikipedia_file_data['prompt_id']==prompt_id]['id'].values)].index.values\n    prompt_context += \"Question: \" + trn.prompt.iloc[prompt_id] + \"\\n\"\n\n    prompt_context += \"Choices:\\n\"\n    prompt_context += \"(A) \" + trn.A.iloc[prompt_id] + \"\\n\"\n    prompt_context += \"(B) \" + trn.B.iloc[prompt_id] + \"\\n\"\n    prompt_context += \"(C) \" + trn.C.iloc[prompt_id] + \"\\n\"\n    prompt_context += \"(D) \" + trn.D.iloc[prompt_id] + \"\\n\"\n    prompt_context += \"(E) \" + trn.E.iloc[prompt_id] + \"\\n\"\n\n    if prompt_indices.shape[0] > 0:\n        prompt_context += \"Context:\\n\"\n        ## Per Prompt Index\n        prompt_index = faiss.index_factory(wiki_data_embeddings.shape[1], \"Flat\")\n        \n        prompt_index.add(wiki_data_embeddings[prompt_indices])\n        \n\n        context = \"\"\n        \n        ## Get the top matches\n        ss, ii = prompt_index.search(question_embeddings, NUM_SENTENCES_INCLUDE)\n        for _s, _i in zip(ss[prompt_id], ii[prompt_id]):\n            ## Threshold on the score\n            if _s < 2:\n                context += processed_wiki_text_data.loc[prompt_indices]['text'].iloc[_i] + \"\\n\"\n        prompt_context += context\n        \n        \n    contexts.append(context)\n    prompt_contexts.append(prompt_context)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:35:27.361456Z","iopub.status.idle":"2024-05-22T05:35:27.361960Z","shell.execute_reply.started":"2024-05-22T05:35:27.361691Z","shell.execute_reply":"2024-05-22T05:35:27.361712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn['context'] = contexts","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:35:27.363270Z","iopub.status.idle":"2024-05-22T05:35:27.363752Z","shell.execute_reply.started":"2024-05-22T05:35:27.363499Z","shell.execute_reply":"2024-05-22T05:35:27.363517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn = trn.drop('answer_all', axis=1)\ntrn = trn.drop('prompt_answer_stem', axis=1)\ntrn","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:35:27.365409Z","iopub.status.idle":"2024-05-22T05:35:27.365879Z","shell.execute_reply.started":"2024-05-22T05:35:27.365633Z","shell.execute_reply":"2024-05-22T05:35:27.365653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn.to_csv(\"./train_context.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:35:27.367890Z","iopub.status.idle":"2024-05-22T05:35:27.368263Z","shell.execute_reply.started":"2024-05-22T05:35:27.368099Z","shell.execute_reply":"2024-05-22T05:35:27.368113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, p in enumerate(prompt_contexts[:10]):\n    print(f\"Question {i}\")\n    print(p)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:35:27.369143Z","iopub.status.idle":"2024-05-22T05:35:27.369478Z","shell.execute_reply.started":"2024-05-22T05:35:27.369308Z","shell.execute_reply":"2024-05-22T05:35:27.369322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}